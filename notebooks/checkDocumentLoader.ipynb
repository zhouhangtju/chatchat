{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebc9b88-8caa-4a93-b4ae-59f53f66f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95610af-10ea-45d9-88e2-f3ae36d3adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the 'punkt' tokenizer\n",
    "# nltk.download('punkt')\n",
    "\n",
    "for pkg in ['punkt', 'averaged_perceptron_tagger']:\n",
    "    nltk.download(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793ca3e2-5141-461f-b246-e66d09963dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RapidOCRPDFLoader context page index: 2744: 100%|██████████| 2745/2745 [01:14<00:00, 36.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "<class 'str'>\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from configs import PDF_OCR_THRESHOLD\n",
    "from document_loaders.ocr import get_ocr\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class RapidOCRPDFLoader(UnstructuredFileLoader):\n",
    "    def _get_elements(self) -> List:\n",
    "        def rotate_img(img, angle):\n",
    "            '''\n",
    "            img   --image\n",
    "            angle --rotation angle\n",
    "            return--rotated img\n",
    "            '''\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            rotate_center = (w/2, h/2)\n",
    "            #获取旋转矩阵\n",
    "            # 参数1为旋转中心点;\n",
    "            # 参数2为旋转角度,正值-逆时针旋转;负值-顺时针旋转\n",
    "            # 参数3为各向同性的比例因子,1.0原图，2.0变成原来的2倍，0.5变成原来的0.5倍\n",
    "            M = cv2.getRotationMatrix2D(rotate_center, angle, 1.0)\n",
    "            #计算图像新边界\n",
    "            new_w = int(h * np.abs(M[0, 1]) + w * np.abs(M[0, 0]))\n",
    "            new_h = int(h * np.abs(M[0, 0]) + w * np.abs(M[0, 1]))\n",
    "            #调整旋转矩阵以考虑平移\n",
    "            M[0, 2] += (new_w - w) / 2\n",
    "            M[1, 2] += (new_h - h) / 2\n",
    "\n",
    "            rotated_img = cv2.warpAffine(img, M, (new_w, new_h))\n",
    "            return rotated_img\n",
    "        \n",
    "        def pdf2text(filepath):\n",
    "            import fitz # pyMuPDF里面的fitz包，不要与pip install fitz混淆\n",
    "            import numpy as np\n",
    "            ocr = get_ocr()\n",
    "            doc = fitz.open(filepath)\n",
    "            resp = \"\"\n",
    "\n",
    "            b_unit = tqdm.tqdm(total=doc.page_count, desc=\"RapidOCRPDFLoader context page index: 0\")\n",
    "            for i, page in enumerate(doc):\n",
    "                b_unit.set_description(\"RapidOCRPDFLoader context page index: {}\".format(i))\n",
    "                b_unit.refresh()\n",
    "                text = page.get_text(\"\")\n",
    "                resp += text + \"\\n\"\n",
    "\n",
    "                img_list = page.get_image_info(xrefs=True)\n",
    "                for img in img_list:\n",
    "                    if xref := img.get(\"xref\"):\n",
    "                        bbox = img[\"bbox\"]\n",
    "                        # 检查图片尺寸是否超过设定的阈值\n",
    "                        if ((bbox[2] - bbox[0]) / (page.rect.width) < PDF_OCR_THRESHOLD[0]\n",
    "                            or (bbox[3] - bbox[1]) / (page.rect.height) < PDF_OCR_THRESHOLD[1]):\n",
    "                            continue\n",
    "                        pix = fitz.Pixmap(doc, xref)\n",
    "                        samples = pix.samples\n",
    "                        if int(page.rotation)!=0:  #如果Page有旋转角度，则旋转图片\n",
    "                            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, -1)\n",
    "                            tmp_img = Image.fromarray(img_array);\n",
    "                            ori_img = cv2.cvtColor(np.array(tmp_img),cv2.COLOR_RGB2BGR)\n",
    "                            rot_img = rotate_img(img=ori_img, angle=360-page.rotation)\n",
    "                            img_array = cv2.cvtColor(rot_img, cv2.COLOR_RGB2BGR)\n",
    "                        else:\n",
    "                            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, -1)\n",
    "\n",
    "                        result, _ = ocr(img_array)\n",
    "                        if result:\n",
    "                            ocr_result = [line[1] for line in result]\n",
    "                            resp += \"\\n\".join(ocr_result)\n",
    "\n",
    "                # 更新进度\n",
    "                b_unit.update(1)\n",
    "            return resp\n",
    "\n",
    "        text = pdf2text(self.file_path)\n",
    "        print(\"#\")\n",
    "        print(type(text))\n",
    "        # 打开文件，模式为写入模式，如果文件不存在会自动创建\n",
    "        with open(\"/root/llm/Langchain-Chatchat-master/notebooks/output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "            # 将字符串写入文件\n",
    "            file.write(text) \n",
    "        \n",
    "        from unstructured.partition.text import partition_text\n",
    "        return partition_text(text=text, **self.unstructured_kwargs)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "file_path = \"/root/llm/Langchain-Chatchat-master/data/厂家产品手册/锐捷/20210910211119_RG-S6000E系列交换机RGOS 11.4(1)B12P32S1版本配置手册(V1.0).pdf\"\n",
    "loader = RapidOCRPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"##########\")\n",
    "# print(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f6c687f-18d5-4326-95fe-eb2b26b02f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'       lost+found  rgos        sys\\n\\n【检验方法】\\n\\n1-8\\n\\n配置指南\\n\\n诊断命令\\n\\n常见错误\\n\\n\\uf03d\\n\\n同一时刻，只允许一个终端执行诊断命令。\\n\\n1.5 监视与维'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec7cb9c-072a-4dad-8930-1e640799dd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'配置手册\\n\\nRG-S6000E 系列交换机\\n\\nS6000E_RGOS11.4(1)B12P32S1\\n\\n文档版本 ：V1.0\\n\\ncopyright © 2021 锐捷网络\\n\\n版权声明\\n\\ncopyright © 2021 锐捷网络\\n\\n保留对本文档及本声明的一切权利。\\n\\n未得到锐捷网络的书面许可，任何单位和个人不得以任何方式或形式对本文档的部分内容或全部进行复制、摘录、备份、修\\n\\n改、传播、翻译成其他语言、将其全部或部分用于商业用途。\\n\\n以上均为锐捷网络的商标。\\n\\n本文档提及的其他所有商标或注册商标，由各自的所有人拥有。\\n\\n免责声明\\n\\n您所购买的产品、服务或特性等应受商业合同和条款的约束，本文档中描述的全部或部分产品、服务或特性可能不在您的购\\n\\n买或使用范围之内。除非合同另有约定，锐捷网络对本文档内容不做任何明示或默示的声明或保证。\\n\\n由于产品版本升级或其他原因，本文档内容会不定期进行更新。锐捷网络保留在没有任何通知或者提示的情况下对文档内容\\n\\n进行修改的权利。\\n\\n本手册仅作为使用指导。锐捷网络在编写本手册时已尽力保证其内容准确可靠，但并不确保手册内容完全没有错误或遗漏，\\n\\n本手册中的所有信息也不构成任何明示或暗示的担保。\\n\\n前言\\n\\n读者对象\\n\\n本书适合下列人员阅读\\n\\n\\uf06c\\n\\n网络工程师\\n\\n\\uf06c\\n\\n技术推广人员\\n\\n\\uf06c\\n\\n网络管理员\\n\\n技术支持\\n\\n\\uf06c\\n\\n锐捷网络官方网站：http://www.ruijie.com.cn/\\n\\n\\uf06c\\n\\n锐捷网络在线客服：http://webchat.ruijie.com.cn\\n\\n\\uf06c\\n\\n锐捷网络官方网站服务与支持版块：http://www.ruijie.com.cn/service.aspx\\n\\n\\uf06c\\n\\n7×24 小时技术服务热线：4008-111-000\\n\\n\\uf06c\\n\\n锐捷网络技术论坛：http://bbs.ruijie.com.cn/portal.php\\n\\n\\uf06c\\n\\n常见问题搜索：http://www.ruijie.com.cn/service/know.aspx\\n\\n\\uf06c\\n\\n锐捷网络技术支持与反馈信箱：4008111000@ruijie.com.cn\\n\\n本书约定\\n\\n1.\\n\\n命令行格式约定\\n\\n命令行格式意义如下：\\n\\n粗体：命令行关键字（命令中保持不变必须照输的部分）采用加粗字体表示。\\n\\n斜体：命令行参数（命令中必须由实际值进行替代的部分）采用斜体表示\\n\\n[ ] ：表示用[ ] 括起来的部分，在命令配置时是可选的。\\n\\n{ x | y | ... }：表示从两个或多个选项中选取一个。\\n\\n[ x | y | ... ]：表示从两个或多个选项中选取一个或者不选。\\n\\n//：由双斜杠开始的行表示为注释行。\\n\\n2.\\n\\n各类标志\\n\\n本书还采用各种醒目标志来表示在操作过程中应该特别注意的地方，这些标志的意义如下：\\n\\n警告标志。表示用户必须严格遵守的规则。如果忽视此类信息，可能导致人身危险或设备损坏。\\n\\n注意标志。表示用户必须了解的重要信息。如果忽视此类信息，可能导致功能失效或性能降低。\\n\\n说明标志。用于提供补充、申明、提示等。如果忽视此类信息，不会导致严重后果。\\n\\n产品/版本支持情况标志。用于提供产品或版本支持情况的说明。\\n\\n3.\\n\\n说明\\n\\n\\uf06c\\n\\n本手册举例说明部分的端口类型同实际可能不符，实际操作中需要按照各产品所支持的端口类型进行配置。\\n\\n\\uf06c\\n\\n本手册部分举例的显示信息中可能含有其它产品系列的内容（如产品型号、描述等），具体显示信息请以实际使用的设\\n\\n备信息为准。\\n\\n\\uf06c\\n\\n本手册中涉及的路由器及路由器产品图标，代表了一般意义下的路由器，以及运行了路由协议的三层交换机。\\n\\n配置指南-系统配置\\n\\n本分册介绍系统配置配置指南相关内容，包括以下章节：\\n\\n1.\\n\\n命令行界面\\n\\n2.\\n\\n基础管理\\n\\n3.\\n\\nLINE\\n\\n4.\\n\\nTIME RANGE\\n\\n5.\\n\\nHTTP 服务\\n\\n6.\\n\\n系统日志\\n\\n7.\\n\\nCWMP\\n\\n8.\\n\\nZAM\\n\\n9.\\n\\nMONITOR\\n\\n10. 模块热插拔\\n\\n11. 管理板冗余\\n\\n12. USB\\n\\n13. UFT\\n\\n14. PKG_MGMT\\n\\n15. PYTHON SHELL\\n\\n1-1\\n\\n配置指南\\n\\n命令行界面\\n\\n1 命令行界面\\n\\n1.1 概述\\n\\n命令行界面(Command Line Interface，CLI)是用户与网络设备进行文本指令交互的窗口，用户可以在命令行界面输入命令，实\\n\\n现对网络设备的配置和管理。\\n\\n协议规范\\n\\n命令行界面无对应的协议规范。\\n\\n1.2 典型应用\\n\\n典型应用\\n\\n场景描述\\n\\n通过 CLI 配置管理网络设备\\n\\n通过在命令行界面输入命令对网络设备进行配置管理。\\n\\n1.2.1 通过 CLI 配置管理网络设备\\n\\n应用场景\\n\\n以下图为例，用户通过终端登录网络设备 A，在命令行界面输入命令实现对设备的配置管理。\\n\\n图 1-1\\n\\n【注释】\\n\\nA 为需要被管理的网络设备\\n\\nPC 为用户端。\\n\\n功能部署\\n\\n下图列举了在 PC 上通过 Secure CRT 与网络设备 A 建立连接，并打开命令行界面配置命令。\\n\\n图 1-2\\n\\n1-2\\n\\n配置指南\\n\\n命令行界面\\n\\n1.3 功能详解\\n\\n功能特性\\n\\n功能特性\\n\\n作用\\n\\n访问 CLI\\n\\n登录网络设备进行配置管理。\\n\\n命令模式\\n\\n命令行接口分为若干种命令模式，不同的命令模式可使用的命令不同。\\n\\n系统帮助\\n\\n用户在 CLI 配置过程中可获取系统的帮助信息。\\n\\n简写命令\\n\\n如果输入的字符足够识别唯一的命令关键字，可以不必完整输入。\\n\\n命令的 no 和 default 选项\\n\\n通过 no 或 default 命令，禁止某个功能特性、执行与命令本身相反的操作或恢复缺省配置。\\n\\n错误命令的提示信息\\n\\n当用户输入错误命令时，会弹出相应的错误提示信息。\\n\\n历史命令\\n\\n用户可以通过快捷键的方式查询、调用历史命令。\\n\\n编辑特性\\n\\n系统提供相关快捷键便于用户编辑命令。\\n\\nshow 命令的查找和过滤\\n\\n用户可以在 show 命令输出的信息中查找或过滤指定的内容。\\n\\n命令别名\\n\\n配置命令的别名，可以替代命令执行配置。\\n\\n1.3.1 访问 CLI\\n\\n在使用 CLI 之前，用户需要通过一个终端或 PC 和网络设备连接。启动网络设备，在网络设备硬件和软件初始化后就可以使用\\n\\nCLI。在首次使用网络设备时，只能通过串口（Console）连接网络设备，称为带外（Out band）管理方式。在进行了相关配\\n\\n置后，还可以通过 Telnet 虚拟终端方式连接和管理网络设备。\\n\\n1.3.2 命令模式\\n\\n设备可供使用的命令非常多，为便于使用这些命令，将命令按功能进行分类。命令行接口分为若干个命令模式，所有命令都注\\n\\n册在某种（或几种）命令模式下。当使用某条命令时，需要先进入这个命令所在的模式。不同的命令模式之间既有联系又有区\\n\\n别。\\n\\n当用户和网络设备管理界面建立一个新的会话连接时，用户首先处于用户模式（User EXEC 模式）。在此模式下，只可以使\\n\\n用少量命令，并且命令的功能也受到一些限制，例如像 show 命令等。用户模式的命令的操作结果不会被保存。\\n\\n1-3\\n\\n配置指南\\n\\n命令行界面\\n\\n要使用更多的命令，首先须进入特权模式（Privileged EXEC 模式）。通常，在进入特权模式时必须输入特权模式的口令。在\\n\\n特权模式下，用户可以使用所有的特权命令，并且能够由此进入全局配置模式。\\n\\n使用配置模式（全局配置模式、接口配置模式等）的命令，会对当前运行的配置产生影响。如果用户保存了配置信息，这些命\\n\\n令将被保存下来，并在系统重新启动时再次执行。要进入各种配置模式，首先必须进入全局配置模式。在全局配置模式下配置，\\n\\n可以进入接口配置模式等各种配置子模式。\\n\\n各个命令模式概要如下（假定网络设备的名字为缺省的“Ruijie”）：\\n\\n命令模式\\n\\n访问方法\\n\\n提示符\\n\\n离开或访问下一模式\\n\\n关于该模式\\n\\nUser EXEC\\n\\n(用户模式)\\n\\n访问网络设备时默认\\n\\n进入该模式。\\n\\nRuijie>\\n\\n输入 exit 命令离开该模式。\\n\\n要进入特权模式，输入 enable\\n\\n命令。\\n\\n使用该模式来进行\\n\\n基本测试、显示系\\n\\n统信息。\\n\\nPrivileged EXEC\\n\\n(特权模式)\\n\\n在用户模式下，使用\\n\\nenable 命令进入该模\\n\\n式。\\n\\nRuijie#\\n\\n要 返 回 到 用 户 模 式 ， 输 入\\n\\ndisable 命令。\\n\\n要 进 入 全 局 配 置 模 式 ， 输 入\\n\\nconfigure 命令。\\n\\n使用该模式来验证\\n\\n设置命令的结果。\\n\\n该模式是具有口令\\n\\n保护的。\\n\\nGlobal configuration\\n\\n(全局配置模式)\\n\\n在特权模式下，使用\\n\\nconfigure 命令进入\\n\\n该模式。\\n\\nRuijie(config)#\\n\\n要返回到特权模式，输入 exit\\n\\n命令或 end 命令，或者键入\\n\\nCtrl+C 组合键。\\n\\n要 进 入 接 口 配 置 模 式 ， 输 入\\n\\ninterface 命令。在 interface\\n\\n命令中必须指明要进入哪一个\\n\\n接口配置子模式。\\n\\n要进入 VLAN 配置模式，输入\\n\\nvlan vlan_id 命令。\\n\\n使用该模式的命令\\n\\n来配置影响整个网\\n\\n络 设 备 的 全 局 参\\n\\n数。\\n\\nInterface configuration\\n\\n(接口配置模式)\\n\\n在全局配置模式下，\\n\\n使用 interface 命令\\n\\n进入该模式。\\n\\nRuijie(config-if)#\\n\\n要返回到特权模式，输入 end\\n\\n命令，或键入 Ctrl+C 组合键。\\n\\n要返回到全局配置模式，输入\\n\\nexit 命令。在 interface 命令中\\n\\n必须指明要进入哪一个接口配\\n\\n置子模式。\\n\\n使用该模式配置网\\n\\n络 设 备 的 各 种 接\\n\\n口。\\n\\nConfig-vlan\\n\\n(VLAN 配置模式)\\n\\n在全局配置模式下，\\n\\n使用 vlan vlan_id 命\\n\\n令进入该模式。\\n\\nRuijie(config-vlan)#\\n\\n要返回到特权模式，输入 end\\n\\n命令，或键入 Ctrl+C 组合键。\\n\\n要返回到全局配置模式，输入\\n\\nexit 命令。\\n\\n使 用 该 模 式 配 置\\n\\nVLAN 参数。\\n\\n1.3.3 系统帮助\\n\\n用户在输入命令行的过程中，可以通过如下方式获取系统帮助。\\n\\n1.\\n\\n在任意模式的命令提示符下，输入问号（?）列出当前命令模式支持的命令及其描述信息。\\n\\n1-4\\n\\n配置指南\\n\\n命令行界面\\n\\n例如：\\n\\nRuijie>?\\n\\nExec commands:\\n\\n<1-99>      Session number to resume\\n\\ndisable     Turn off privileged commands\\n\\ndisconnect  Disconnect an existing network connection\\n\\nenable      Turn on privileged commands\\n\\nexit        Exit from the EXEC\\n\\nhelp        Description of the interactive help system\\n\\nlock        Lock the terminal\\n\\nping        Send echo messages\\n\\nshow        Show running system information\\n\\ntelnet      Open a telnet connection\\n\\ntraceroute  Trace route to destination\\n\\n2.\\n\\n在一条命令的关键字后空格并输入问号（?），可以列出该关键字关联的下一个关键字或变量。\\n\\n例如：\\n\\nRuijie(config)#interface ?\\n\\nAggregateport     Aggregate port interface\\n\\nDialer            Dialer interface\\n\\nGigabitEthernet   Gigabit Ethernet interface\\n\\nLoopback          Loopback interface\\n\\nMultilink         Multilink-group  interface\\n\\nNull              Null interface\\n\\nTunnel            Tunnel interface\\n\\nVirtual-ppp       Virtual PPP interface\\n\\nVirtual-template  Virtual Template interface\\n\\nVlan              Vlan interface\\n\\nrange             Interface range command\\n\\n如果该关键字后带的是一个参数值，则列出该参数的取值范围及其描述信息，如下所示：\\n\\nRuijie(config)#interface vlan ?\\n\\n<1-4094>  Vlan port number\\n\\n3.\\n\\n在输入不完整的命令关键字后输入问号（?），可以列出以该字符串开头的所有命令关键字。\\n\\n例如：\\n\\nRuijie#d?\\n\\ndebug  delete  diagnostic  dir  disable  disconnect\\n\\n4.\\n\\n在输入不完整的命令关键字后，如果该关键字后缀唯一，可以键入<Tab>键生成完整关键字。\\n\\n例如：\\n\\nRuijie# show conf<Tab>\\n\\n1-5\\n\\n配置指南\\n\\n命令行界面\\n\\nRuijie# show configuration\\n\\n5.\\n\\n在任何命令模式下，还可以通过 help 命令获取帮助系统的摘要描述信息。\\n\\n例如：\\n\\nRuijie(config)#help\\n\\nHelp may be requested at any point in a command by entering\\n\\na question mark \\'?\\'. If nothing matches, the help list will\\n\\nbe empty and you must backup until entering a \\'?\\' shows the\\n\\navailable options.\\n\\nTwo styles of help are provided:\\n\\n1. Full help is available when you are ready to enter a\\n\\ncommand argument (e.g. \\'show ?\\') and describes each possible\\n\\nargument.\\n\\n2. Partial help is provided when an abbreviated argument is entered\\n\\nand you want to know what arguments match the input\\n\\n(e.g. \\'show pr?\\'.)\\n\\n1.3.4 简写命令\\n\\n如果命令比较长，想简写命令，只需要输入命令关键字的一部分字符，且这部分字符足够识别唯一的命令关键字即可。\\n\\n例如进入 GigabitEthernet 0/1 接口配置模式的命令“interface gigabitEthernet 0/1”可以简写成：\\n\\nRuijie(config)#int g0/1\\n\\nRuijie(config-if-GigabitEthernet 0/1)#\\n\\n1.3.5 命令的 no 和 default 选项\\n\\n大部分命令有 no 选项。通常，使用 no 选项来禁止某个特性或功能，或者执行与命令本身相反的操作。例如接口配置命令 no\\n\\nshutdown 执行关闭接口命令 shutdown 的相反操作，即打开接口。使用不带 no 选项的关键字，打开被关闭的特性或者打开\\n\\n缺省是关闭的特性。\\n\\n配置命令大多有 default 选项，命令的 default 选项将命令的设置恢复为缺省值。大多数命令的缺省值是禁止该功能，因此在\\n\\n许多情况下 default 选项的作用和 no 选项是相同的。然而部分命令的缺省值是允许该功能，在这种情况下，default 选项和\\n\\nno 选项的作用是相反的。这时 default 选项打开该命令的功能，并将变量设置为缺省的允许状态。\\n\\n各命令的 no 或 default 选项作用请参见相应的命令手册。\\n\\n1.3.6 错误命令的提示信息\\n\\n当用户输入错误命令时，会弹出相应的错误提示信息。\\n\\n常见的 CLI 错误信息：\\n\\n1-6\\n\\n配置指南\\n\\n命令行界面\\n\\n错误信息\\n\\n含义\\n\\n如何获取帮助\\n\\n% Ambiguous command: \"show\\n\\nc\"\\n\\n用户没有输入足够的字符，网络设备\\n\\n无法识别唯一的命令。\\n\\n重新输入命令，紧接着发生歧义的单词输入一个问\\n\\n号。可能输入的关键字将被显示出来。\\n\\n% Incomplete command.\\n\\n用户没有输入该命令的必需的关键\\n\\n字或者变量参数。\\n\\n重新输入命令，输入空格再输入一个问号。可能输入\\n\\n的关键字或者变量参数将被显示出来。\\n\\n% Invalid input detected at ‘^’\\n\\nmarker.\\n\\n用户输入命令错误，符号（^）指明\\n\\n了产生错误的单词的位置。\\n\\n在所在地命令模式提示符下输入一个问号，该模式允\\n\\n许的命令的关键字将被显示出来。\\n\\n1.3.7 历史命令\\n\\n系统能够自动保存用户最近输入的历史命令，用户可以通过快捷键的方式查询、调用历史命令。\\n\\n操作方法如下：\\n\\n操作\\n\\n结果\\n\\nCtrl-P 或上方向键\\n\\n在历史命令表中浏览前一条命令。从最近的一条记录开始，重复使用该操作可以查询更早的记录。\\n\\nCtrl-N 或下方向键\\n\\n在使用了 Ctrl-P 或上方向键操作之后，使用该操作在历史命令表中回到更近的一条命令。重复使用该\\n\\n操作可以查询更近的记录。\\n\\n标准的终端支持方向键，例如 VT100 系列。\\n\\n1.3.8 编辑特性\\n\\n用户在进行命令行编辑时，可以使用如下按键或快捷键：\\n\\n功能\\n\\n按键、快捷键\\n\\n说明\\n\\n在编辑行内移动光标。\\n\\n左方向键或 Ctrl-B\\n\\n光标移到左边一个字符。\\n\\n右方向键或 Ctrl-F\\n\\n光标移到右边一个字符。\\n\\nCtrl-A\\n\\n光标移到命令行的首部。\\n\\nCtrl-E\\n\\n光标移到命令行的尾部。\\n\\n删除输入的字符。\\n\\nBackspace 键\\n\\n删除光标左边的一个字符。\\n\\nDelete 键\\n\\n删除光标右边的一个字符。\\n\\n输出时屏幕滚动一行或一页。\\n\\nReturn 键\\n\\n在显示内容时用回车键将输出的内容向上滚动一行，显示下一行的\\n\\n内容，仅在输出内容未结束时使用。\\n\\nSpace 键\\n\\n在显示内容时用空格键将输出的内容向上滚动一页，显示下一页内\\n\\n容，仅在输出内容未结束时使用。\\n\\n当编辑的光标接近右边界时，命令行会整体向左移动 20 个字符，命令行前部被隐藏的部分被符号（$）代替，可以使用相关按\\n\\n键或快捷键将光标移到前面的字符或者回到命令行的首部。\\n\\n例如配置模式的命令 access-list 的输入可能超过一个屏幕的宽度。当光标第一次接近行尾时，命令行整体向左移动 20 个字符，\\n\\n命令行前部被隐藏的部分被符号（$）代替。每次接近右边界时都会向左移动 20 个字符长度。\\n\\naccess-list 199 permit ip host 192.168.180.220 host\\n\\n1-7\\n\\n配置指南\\n\\n命令行界面\\n\\n$ost 192.168.180.220 host 202.101.99.12\\n\\n$0.220 host 202.101.99.12 time-range tr\\n\\n可以使用 Ctrl-A 快捷键回到命令行的首部，这时命令行尾部被隐藏的部分将被符号（$）代替：\\n\\naccess-list 199 permit ip host 192.168.180.220 host 202.101.99.$\\n\\n默认的终端行宽是 80 个字符。\\n\\n1.3.9 show 命令的查找和过滤\\n\\n要在 show 命令输出的信息中查找指定的内容，可以在使用以下命令：\\n\\n命令\\n\\n作用\\n\\nshow any-command | begin regular-expression\\n\\n在 show 命令的输出内容中查找指定的内容，将第一个包含该\\n\\n内容的行以及该行以后的全部信息输出。\\n\\n支持在任意模式下执行 show 命令。\\n\\n查找的信息内容需要区分大小写，以下相同。\\n\\n要在 show 命令的输出信息中过滤指定的内容，可以使用以下命令：\\n\\n命令\\n\\n作用\\n\\nshow any-command | exclude regular-expression\\n\\n在 show 命令的输出内容中进行过滤，除了包含指定内容的行\\n\\n以外，输出其他的信息内容。\\n\\nshow any-command | include regular-expression\\n\\n在 show 命令的输出内容中进行过滤，仅输出包含指定内容的\\n\\n行，其他信息将被过滤。\\n\\n要在 show 命令的输出内容中进行查找和过滤，需要输入管道符号（竖线，”|”）。在管道字符之后，可以选择查找和过滤的规\\n\\n则和查找和过滤的内容（字符或字符串），并且查找和过滤的内容需要区分大小写：\\n\\nRuijie#show running-config | include interface\\n\\ninterface GigabitEthernet 0/0\\n\\ninterface GigabitEthernet 0/1\\n\\ninterface GigabitEthernet 0/2\\n\\ninterface GigabitEthernet 0/3\\n\\ninterface GigabitEthernet 0/4\\n\\ninterface GigabitEthernet 0/5\\n\\ninterface GigabitEthernet 0/6\\n\\ninterface GigabitEthernet 0/7\\n\\ninterface Mgmt 0\\n\\n1.3.10 命令别名\\n\\n用户可以指定任意单词作为命令的别名，来简化命令行字符串的输入。\\n\\n1-8\\n\\n配置指南\\n\\n命令行界面\\n\\n配置效果\\n\\n6.\\n\\n一个单词代替一条命令。\\n\\n例如：将“ip route 0.0.0.0 0.0.0.0192.1.1.1”配置别名“mygateway”，执行该命令只要输入“mygateway”即可。\\n\\n7.\\n\\n一个单词代替一条命令的前半部分，再输入后半部分。\\n\\n例如：将“ip address”配置别名“ia”，执行 IP 地址配置可以先输入“ia”，再输入指定的 IP 地址及掩码。\\n\\n配置方法\\n\\n\\uf0e6\\n\\n系统默认别名\\n\\n\\uf06c\\n\\n在普通或特权用户模式下，部分命令存在默认的别名，可以通过 show aliases 命令查看：\\n\\nRuijie(config)#show aliases\\n\\nExec mode alias:\\n\\nh                    help\\n\\np                    ping\\n\\ns                    show\\n\\nu                    undebug\\n\\nun                   undebug\\n\\n这些默认的别名不能删除。\\n\\n\\uf0e6\\n\\n配置命令别名\\n\\n\\uf06c\\n\\n相关命令如下：\\n\\n【命令格式】\\n\\nalias mode command-alias original-command\\n\\n【参数说明】\\n\\nmode：别名所代表的命令所处的命令模式。\\n\\ncommand-alias：命令别名。\\n\\noriginal-command：别名所代表的实际命令。\\n\\n【命令模式】\\n\\n全局模式\\n\\n【使用指导】\\n\\n在全局配置模式下，输入 alias ?可以列出当前可以配置别名的全部命令模式。\\n\\n\\uf0e6\\n\\n查看命令别名设置\\n\\n使用 show aliases 命令可以查看系统中的别名设置。\\n\\n注意事项\\n\\n\\uf06c\\n\\n别名替代'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cc3d70-0ef8-4a02-9880-8acd24431f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class AliTextSplitter(CharacterTextSplitter):\n",
    "    def __init__(self, pdf: bool = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pdf = pdf\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        # use_document_segmentation参数指定是否用语义切分文档，此处采取的文档语义分割模型为达摩院开源的nlp_bert_document-segmentation_chinese-base，论文见https://arxiv.org/abs/2107.09278\n",
    "        # 如果使用模型进行文档语义切分，那么需要安装modelscope[nlp]：pip install \"modelscope[nlp]\" -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html\n",
    "        # 考虑到使用了三个模型，可能对于低配置gpu不太友好，因此这里将模型load进cpu计算，有需要的话可以替换device为自己的显卡id\n",
    "        if self.pdf:\n",
    "            text = re.sub(r\"\\n{3,}\", r\"\\n\", text)\n",
    "            text = re.sub('\\s', \" \", text)\n",
    "            text = re.sub(\"\\n\\n\", \"\", text)\n",
    "        try:\n",
    "            from modelscope.pipelines import pipeline\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import modelscope python package. \"\n",
    "                \"Please install modelscope with `pip install modelscope`. \"\n",
    "            )\n",
    "\n",
    "\n",
    "        p = pipeline(\n",
    "            task=\"document-segmentation\",\n",
    "            model='/root/model/ali/nlp_bert_document-segmentation_chinese-base',\n",
    "            device=\"gpu\")\n",
    "        result = p(documents=text)\n",
    "        sent_list = [i for i in result[\"text\"].split(\"\\n\\t\") if i]\n",
    "        return sent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900c6e2f-abdf-4ce1-8bd7-fb826e57379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"output-Copy1.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9190be-2b78-4bac-b628-3e42f9dec4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n配置手册 \\nRG'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38986017-5cca-45ac-a2ff-08dc26be8a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 14:46:39,665 - modelscope - INFO - PyTorch version 2.1.2 Found.\n",
      "2024-06-07 14:46:39,820 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-06-07 14:46:43,290 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 521f86a77a0a91aeebd5bf646b81ffed and a total number of 976 components indexed\n",
      "/root/.local/conda/envs/chatchat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-07 14:47:36,237 - modelscope - INFO - initiate model from /root/model/ali/nlp_bert_document-segmentation_chinese-base\n",
      "2024-06-07 14:47:36,239 - modelscope - INFO - initiate model from location /root/model/ali/nlp_bert_document-segmentation_chinese-base.\n",
      "2024-06-07 14:47:36,241 - modelscope - INFO - initialize model from /root/model/ali/nlp_bert_document-segmentation_chinese-base\n",
      "/root/.local/conda/envs/chatchat/lib/python3.11/site-packages/transformers/configuration_utils.py:365: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/root/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2024-06-07 14:47:43,675 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-07 14:47:43,677 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-07 14:47:43,678 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/model/ali/nlp_bert_document-segmentation_chinese-base'}. trying to build by task and model information.\n",
      "2024-06-07 14:47:43,679 - modelscope - WARNING - No preprocessor key ('bert-for-document-segmentation', 'document-segmentation') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "/root/.local/conda/envs/chatchat/lib/python3.11/site-packages/transformers/modeling_utils.py:993: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 40.39 GiB. GPU 0 has a total capacty of 31.74 GiB of which 605.12 MiB is free. Process 3200058 has 31.14 GiB memory in use. Of the allocated memory 30.73 GiB is allocated by PyTorch, and 49.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m spliter \u001b[38;5;241m=\u001b[39m AliTextSplitter()\n\u001b[0;32m----> 2\u001b[0m sent_list \u001b[38;5;241m=\u001b[39m \u001b[43mspliter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m, in \u001b[0;36mAliTextSplitter.split_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import modelscope python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install modelscope with `pip install modelscope`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     28\u001b[0m p \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     29\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument-segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/model/ali/nlp_bert_document-segmentation_chinese-base\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m sent_list \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sent_list\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/pipelines/nlp/document_segmentation_pipeline.py:65\u001b[0m, in \u001b[0;36mDocumentSegmentationPipeline.__call__\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m, documents: Union[List[List[\u001b[38;5;28mstr\u001b[39m]], List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     64\u001b[0m                                \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 65\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(output)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/pipelines/nlp/document_segmentation_pipeline.py:103\u001b[0m, in \u001b[0;36mDocumentSegmentationPipeline.predict\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    100\u001b[0m         key: torch\u001b[38;5;241m.\u001b[39mtensor(val)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m predict_dataset\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    102\u001b[0m     }\n\u001b[0;32m--> 103\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    105\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentences) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    107\u001b[0m     predictions), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m  infer_sample \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m prediction \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    108\u001b[0m         num_samples, \u001b[38;5;28mlen\u001b[39m(sentences), \u001b[38;5;28mlen\u001b[39m(predictions))\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/document_segmentation.py:53\u001b[0m, in \u001b[0;36mBertForDocumentSegmentation.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, sentence_attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     40\u001b[0m             input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m             return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentence_pooler_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/base/base_torch_model.py:36\u001b[0m, in \u001b[0;36mTorchModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/backbone.py:901\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask,\n\u001b[1;32m    892\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    894\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    895\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    896\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    900\u001b[0m )\n\u001b[0;32m--> 901\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    914\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(\n\u001b[1;32m    915\u001b[0m     sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/backbone.py:530\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    522\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    523\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/backbone.py:406\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    395\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m ):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\n\u001b[1;32m    405\u001b[0m                                               \u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/backbone.py:327\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    319\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m ):\n\u001b[0;32m--> 327\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    337\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,\n\u001b[1;32m    338\u001b[0m                ) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/conda/envs/chatchat/lib/python3.11/site-packages/modelscope/models/nlp/bert/backbone.py:213\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    210\u001b[0m     past_key_value \u001b[38;5;241m=\u001b[39m (key_layer, value_layer)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_key\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_key_query\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    217\u001b[0m     seq_length \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 40.39 GiB. GPU 0 has a total capacty of 31.74 GiB of which 605.12 MiB is free. Process 3200058 has 31.14 GiB memory in use. Of the allocated memory 30.73 GiB is allocated by PyTorch, and 49.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "spliter = AliTextSplitter()\n",
    "sent_list = spliter.split_text(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa402b0b-0e81-4359-9a4e-d7aa0e323a0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sent_list[0]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdocs\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "sent_list[0]\n",
    "# docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2920155-92d7-46e1-a9bc-caf503d0d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 11:23:32,622 - modelscope - WARNING - Model revision not specified, use revision: v1.0.1\n",
      "Downloading: 100%|██████████| 16.0/16.0 [00:00<00:00, 60.2kB/s]\n",
      "Downloading: 100%|██████████| 1.02k/1.02k [00:00<00:00, 3.74MB/s]\n",
      "Downloading: 100%|██████████| 296/296 [00:00<00:00, 1.14MB/s]\n",
      "Downloading: 100%|██████████| 388M/388M [05:39<00:00, 1.20MB/s] \n",
      "Downloading: 100%|██████████| 5.94k/5.94k [00:00<00:00, 12.4MB/s]\n",
      "Downloading: 100%|██████████| 134/134 [00:00<00:00, 781kB/s]\n",
      "Downloading: 100%|██████████| 263k/263k [00:00<00:00, 1.93MB/s]\n",
      "Downloading: 100%|██████████| 316/316 [00:00<00:00, 1.74MB/s]\n",
      "Downloading: 100%|██████████| 107k/107k [00:00<00:00, 1.22MB/s]\n",
      "Downloading: 100%|██████████| 220k/220k [00:00<00:00, 586kB/s]\n",
      "Downloading: 100%|██████████| 248k/248k [00:00<00:00, 955kB/s]\n"
     ]
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('iic/nlp_bert_document-segmentation_chinese-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "746bf8e7-be5a-4999-b34d-8c730b61ad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 16:35:27,926 - cmapdb.py[line:481] - WARNING: Ignoring (part of) ToUnicode map because the PDF data does not conform to the format. This could result in (cid) values in the output. The start object is not a byte.\n",
      "2024-06-07 16:37:13,780 - cmapdb.py[line:481] - WARNING: Ignoring (part of) ToUnicode map because the PDF data does not conform to the format. This could result in (cid) values in the output. The start object is not a byte.\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "# elements = partition_pdf(\"/root/llm/Langchain-Chatchat-master/notebooks/layout-parser-paper.pdf\")\n",
    "elements = partition_pdf(\"/root/llm/Langchain-Chatchat-master/data/厂家产品手册/锐捷/20210910211119_RG-S6000E系列交换机RGOS 11.4(1)B12P32S1版本配置手册(V1.0).pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "390cf686-d5a7-4cb5-8334-d65bd6b9d1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'配置手册'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(elements[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3825554-722f-466a-9d47-fe9906b39d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下图列举了在 PC 上通过 Secure CRT 与网络设备 A 建立连接，并打开命令行界面配置命令。\n",
      "\n",
      "图 1-2\n",
      "\n",
      "1-1\n",
      "\n",
      "命令行界面\n",
      "\n",
      "配置指南\n",
      "\n",
      "命令行界面\n",
      "\n",
      "1.3 功能详解\n",
      "\n",
      "功能特性\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([str(el) for el in elements[86:94]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d81589-afab-4bcf-b0f8-47ea19ceff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"RG-S6000E/20210910211119_RG-S6000E系列交换机RGOS 11.4(1)B12P32S1版本配置手册(V1.0).pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a502ef88-0f2f-4457-8b1a-f0b70d6f4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n"
     ]
    }
   ],
   "source": [
    "print(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723a6998-9bfc-46b4-956c-7e1106e22371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='4-6 配置指南  VLAN   \\n\\uf0e6 向当前 VLAN添加 ACCESS 口 \\n\\uf06c 可选配置 。 \\n\\uf06c 该命令只对 Access口有效，VLAN添加 Access口后，接口可传输该 VLAN数据。  \\n\\uf06c 交换机设备上配置。  \\n【命令格式】  add interface  { interface -id | range  interface -range  } \\n【参数说明】  interface -id：单个接口  \\ninterface -range：多个接口  \\n【缺省配置】  缺省情况下，所有二层以太网口都属于 VLAN1  \\n【命令模式】  VLAN配置模式  \\n【使用指导】  在VLAN配置模式下，将指定的 Access口加入该 VLAN。该命令的配置效果同在接口模式下指定该接口所属\\nVLAN的命令（即 switchport  access vlan  vlan-id）效果一致。  \\n 对于两种形式的接口加入 VLAN命令，配置生效的原则是后配置的命令覆盖前面配置的命令  \\n检验方法  \\n\\uf06c 往ACCESS 口发送 untag报文，报文在该 VLAN内广播。  \\n\\uf06c 使用命令 show  vlan和show  interface  switchport 查看配置显示是否生效。  \\n【命令格式】  show vlan  [ id vlan-id ] \\n【参数说明】  vlan-id ：VLAN ID 号 \\n【命令模式】  所有模式  \\n【使用指导】  - \\n【命令展示】  Ruijie(config -vlan)#show vlan id 20  \\nVLAN Name                             Status    Ports      \\n---- --------------------------------  ---------  -----------------------------------  \\n  20 VLAN0020                         STATIC    Gi0/1                                \\n配置举例  \\n\\uf0e6 基本 VLAN与access口配置  \\n以下配置举例，仅介绍 VLAN相关的配置。  \\n【配置方法】  \\uf03d 创建一个新 VLAN，并且重命名  \\n\\uf03d 将一个 ACCESS 口加入加入 VLAN，两种方式。  \\n Ruijie# configure terminal  \\nRuijie(config)# vlan 888 \\nRuijie(config-vlan)# name test888 \\nRuijie(config-vlan)# exit \\nRuijie(config)# interface GigabitEthernet  0/3 \\nRuijie(config -if-GigabitEthernet 0/ 3)# switchport mode access  \\nRuijie(config-if-GigabitEthernet 0/ 3)# switchport access vlan 20', metadata={'source': 'RG-S6000E/20210910211119_RG-S6000E系列交换机RGOS 11.4(1)B12P32S1版本配置手册(V1.0).pdf', 'page': 301})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf52909b-c3a7-4553-9296-d40d3ae79842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.35*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667f5f5-698c-4313-9c33-6f0ab53fa778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatchat",
   "language": "python",
   "name": "chatchat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
